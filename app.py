import streamlit as st
import google.generativeai as genai
import requests
import json
import time
import pypdf
import os

# ==========================================
# 1. æ ¸å¿ƒé…ç½®ä¸è®°å¿†æ–‡ä»¶è®¾ç½®
# ==========================================
st.set_page_config(page_title="å¤–è´¸æ•°å­—æŒ‡æŒ¥å®˜ (é•¿æœŸè®°å¿†ç‰ˆ)", page_icon="ğŸ¦", layout="wide")

# å®šä¹‰è®°å¿†æ–‡ä»¶å­˜å‚¨è·¯å¾„ (åœ¨åŒçº§ç›®å½•ä¸‹ç”Ÿæˆä¸€ä¸ª json æ–‡ä»¶)
MEMORY_FILE = "b2b_kb_memory.json"

try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception:
    st.error("âš ï¸ æœªæ£€æµ‹åˆ° API Keyï¼Œè¯·é…ç½® Secretsã€‚")
    st.stop()

# ==========================================
# 2. è®°å¿†ç³»ç»Ÿæ ¸å¿ƒå‡½æ•° (è¯»å†™ç¡¬ç›˜)
# ==========================================
def load_memory():
    """ä»ç¡¬ç›˜è¯»å–è®°å¿†"""
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f).get("text", "")
        except:
            return ""
    return ""

def save_memory(new_text):
    """ä¿å­˜è®°å¿†åˆ°ç¡¬ç›˜ (å¢é‡æ›´æ–°)"""
    current_text = load_memory()
    # é¿å…é‡å¤ä¿å­˜ç›¸åŒå†…å®¹ (ç®€å•å»é‡)
    if new_text not in current_text:
        updated_text = current_text + "\n" + new_text
        with open(MEMORY_FILE, "w", encoding="utf-8") as f:
            json.dump({"text": updated_text}, f, ensure_ascii=False)
        return True
    return False

def clear_memory():
    """å½»åº•æ¸…ç©ºè®°å¿†"""
    if os.path.exists(MEMORY_FILE):
        os.remove(MEMORY_FILE)

# ==========================================
# 3. æ™ºèƒ½å¼•æ“ä¸æŠ—å‹ç³»ç»Ÿ
# ==========================================
@st.cache_resource
def get_best_model():
    return "models/gemini-2.5-flash"

valid_model_name = get_best_model()

def robust_generate(prompt, model_name):
    model = genai.GenerativeModel(model_name)
    for i in range(3):
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            if "429" in str(e):
                time.sleep(5)
                continue
            else:
                return f"âŒ é”™è¯¯: {str(e)}"
    return "âš ï¸ ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åé‡è¯•ã€‚"

def robust_api_search(payload, model_name, api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    for i in range(3):
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 429:
                time.sleep(5)
                continue
            else:
                return {"error": f"Error {response.status_code}"}
        except Exception as e:
            return {"error": str(e)}
    return {"error": "ç½‘ç»œè¶…æ—¶"}

# ==========================================
# 4. ä¾§è¾¹æ ï¼šè®°å¿†ç®¡ç†æ§åˆ¶å°
# ==========================================
st.sidebar.title("ğŸ¦ æ§åˆ¶å°")

st.sidebar.markdown("### ğŸ§  é•¿æœŸè®°å¿†åº“")

# A. åˆå§‹åŒ–ï¼šè¯»å–ç°æœ‰è®°å¿†
current_memory = load_memory()
memory_status = "ğŸŸ¢ è®°å¿†å·²æ¿€æ´»" if current_memory else "âšª è®°å¿†ä¸ºç©º"
st.sidebar.caption(f"çŠ¶æ€: {memory_status}")

if current_memory:
    st.sidebar.info(f"âœ… å·²åŠ è½½è¿‡å¾€èµ„æ–™ ({len(current_memory)} å­—)")
    with st.sidebar.expander("æŸ¥çœ‹å½“å‰è®°å¿†å†…å®¹"):
        st.text(current_memory[:500] + "...") # åªæ˜¾ç¤ºå‰500å­—é¢„è§ˆ

# B. æŠ•å–‚æ–°èµ„æ–™
st.sidebar.markdown("---")
st.sidebar.write("ğŸ“¤ **è¿½åŠ æ–°èµ„æ–™:**")

# 1. æ–‡æœ¬æŠ•å–‚
new_kb_text = st.sidebar.text_area("ç²˜è´´æ–°æ–‡æœ¬:", height=70, placeholder="ç²˜è´´è¡¥å……çš„äº§å“å‚æ•°...")
if st.sidebar.button("ğŸ’¾ ä¿å­˜æ–‡æœ¬åˆ°è®°å¿†"):
    if new_kb_text:
        save_memory(new_kb_text)
        st.sidebar.success("å·²å­˜å…¥å¤§è„‘ï¼è¯·åˆ·æ–°é¡µé¢ç”Ÿæ•ˆã€‚")
        time.sleep(1)
        st.rerun()

# 2. æ–‡ä»¶æŠ•å–‚ (PDF)
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ æ–° PDF:", type=['pdf'], key="pdf_uploader")
if uploaded_file is not None:
    try:
        reader = pypdf.PdfReader(uploaded_file)
        pdf_text = ""
        for page in reader.pages:
            pdf_text += page.extract_text() + "\n"
        
        # è‡ªåŠ¨ä¿å­˜
        if save_memory(pdf_text):
            st.sidebar.success(f"âœ… PDF '{uploaded_file.name}' å·²å­˜å…¥é•¿æœŸè®°å¿†ï¼")
            time.sleep(1)
            st.rerun() # è‡ªåŠ¨åˆ·æ–°é¡µé¢ä»¥æ›´æ–°çŠ¶æ€
    except Exception as e:
        st.sidebar.error("PDF è¯»å–å¤±è´¥")

# C. æ¸…ç©ºè®°å¿†
st.sidebar.markdown("---")
if st.sidebar.button("ğŸ—‘ï¸ æ ¼å¼åŒ–/æ¸…ç©ºæ‰€æœ‰è®°å¿†"):
    clear_memory()
    st.sidebar.warning("è®°å¿†å·²æ“¦é™¤ã€‚")
    time.sleep(1)
    st.rerun()

# ==========================================
# 5. åŠŸèƒ½èœå• (æ³¨å…¥é•¿æœŸè®°å¿†)
# ==========================================
st.sidebar.markdown("---")
MENU_OPTIONS = [
    "ğŸ“§ è¯¢ç›˜æ·±åº¦åˆ†æ", 
    "ğŸ•µï¸â€â™‚ï¸ æ–‡æœ¬èƒŒè°ƒ (ç¨³)", 
    "ğŸŒ å…¨ç½‘æƒ…æŠ¥æ·±æŒ– (è”ç½‘)", 
    "â›” è°ˆåˆ¤ä¸å¼‚è®®ç²‰ç¢",
    "ğŸ› ï¸ æ™ºèƒ½å”®å/ä¸“å®¶é—®ç­”"
]
app_mode = st.sidebar.radio("åŠŸèƒ½é€‰æ‹©ï¼š", MENU_OPTIONS)

# æ„é€ æ³¨å…¥ Prompt (ä½¿ç”¨é•¿æœŸè®°å¿†)
KB_INJECTION = ""
if current_memory:
    KB_INJECTION = f"""
    [IMPORTANT: LONG-TERM COMPANY KNOWLEDGE BASE]
    You have access to the following internal product data/files stored in your memory.
    ALWAYS strictly verify your answers against this data. Do not hallucinate product specs.
    
    {current_memory}
    [END OF KNOWLEDGE BASE]
    """

# ==========================================
# 6. åŠŸèƒ½é€»è¾‘å®ç°
# ==========================================

# --- åŠŸèƒ½ä¸€: è¯¢ç›˜åˆ†æ ---
if app_mode == MENU_OPTIONS[0]: 
    st.subheader("ğŸ“§ æ·±åº¦è¯¢ç›˜åˆ†æ")
    st.caption("AI å°†åŸºäºã€é•¿æœŸè®°å¿†ã€‘ä¸­çš„äº§å“åº“ç”Ÿæˆå›å¤ã€‚")
    user_input = st.text_area("ç²˜è´´å®¢æˆ·é‚®ä»¶ï¼š", height=200)
    
    if 'res_1' not in st.session_state: st.session_state.res_1 = None
    if st.button("ğŸš€ åˆ†æé‚®ä»¶"):
        if not user_input: st.warning("è¯·ç²˜è´´å†…å®¹")
        else:
            with st.spinner('æ­£åœ¨è°ƒå–è®°å¿†åº“åˆ†æ...'):
                PROMPT = f"""
                {KB_INJECTION}
                Act as Sales Manager. Analyze email. 
                If the user asks about products mentioned in the Knowledge Base, use the specific specs/price to answer.
                Output: Language, Intent, Score, Advice, Draft Response.
                """
                res = robust_generate(f"{PROMPT}\nInput: {user_input}", valid_model_name)
                st.session_state.res_1 = res
    if st.session_state.res_1: st.markdown(st.session_state.res_1)

# --- åŠŸèƒ½äºŒ: æ–‡æœ¬èƒŒè°ƒ ---
elif app_mode == MENU_OPTIONS[1]: 
    st.subheader("ğŸ•µï¸â€â™‚ï¸ ç½‘ç«™æ–‡æœ¬åˆ†æ")
    bg_input = st.text_area("ç²˜è´´ç½‘ç«™æ–‡æœ¬ï¼š", height=200)
    
    if 'res_2' not in st.session_state: st.session_state.res_2 = None
    if st.button("ğŸ” åˆ†æèƒŒæ™¯"):
        if not bg_input: st.warning("è¯·ç²˜è´´å†…å®¹")
        else:
            with st.spinner('åˆ†æä¸­...'):
                PROMPT = "Analyze company text. Output: Identity, Scale, Pain Points, Pitch Strategy."
                res = robust_generate(f"{PROMPT}\nText: {bg_input}", valid_model_name)
                st.session_state.res_2 = res
    if st.session_state.res_2: st.markdown(st.session_state.res_2)

# --- åŠŸèƒ½ä¸‰: å…¨ç½‘æ·±æŒ– ---
elif app_mode == MENU_OPTIONS[2]: 
    st.subheader("ğŸŒ å…¨ç½‘å•†ä¸šæƒ…æŠ¥")
    query = st.text_input("å…¬å¸å/å…³é”®è¯ï¼š")
    
    if 'res_3' not in st.session_state: st.session_state.res_3 = None
    if st.button("ğŸŒ æ·±åº¦æŒ–æ˜"):
        if not query: st.warning("è¯·è¾“å…¥å…³é”®è¯")
        else:
            st.session_state.res_3 = None
            with st.spinner('å…¨ç½‘æ£€ç´¢ä¸­...'):
                prompt = f"""
                Role: Senior B2B Analyst. Search: "{query}".
                Report: 1. Identity 2. Latest News 3. Procurement Prediction 4. Competitors 5. Cold Email Hook.
                """
                payload = {"contents": [{"parts": [{"text": prompt}]}], "tools": [{"google_search": {}}]}
                data = robust_api_search(payload, valid_model_name, api_key)
                
                if "error" in data: st.error(data["error"])
                else:
                    try:
                        ans = data['candidates'][0]['content']['parts'][0]['text']
                        grounding = ""
                        try: grounding = data['candidates'][0]['groundingMetadata']['searchEntryPoint']['renderedContent']
                        except: pass
                        st.session_state.res_3 = (grounding, ans)
                    except: st.error("è§£æå¤±è´¥")
    if st.session_state.res_3:
        g, a = st.session_state.res_3
        if g: st.markdown(g, unsafe_allow_html=True)
        st.markdown(a)

# --- åŠŸèƒ½å››: è°ˆåˆ¤ ---
elif app_mode == MENU_OPTIONS[3]: 
    st.subheader("â›” è°ˆåˆ¤ä¸å¼‚è®®ç²‰ç¢æœº")
    st.caption("AI å°†åˆ©ç”¨è®°å¿†ä¸­çš„äº§å“ä¼˜åŠ¿æ¥åå‡»å®¢æˆ·ã€‚")
    
    col1, col2 = st.columns(2)
    with col1: obj = st.text_input("æ‹’ç»ç†ç”±:", placeholder="Price too high")
    with col2: lev = st.text_input("æˆ‘çš„ä¼˜åŠ¿ (ç•™ç©ºåˆ™è‡ªåŠ¨è¯»å–è®°å¿†åº“):")
    
    if 'res_4' not in st.session_state: st.session_state.res_4 = None
    if st.button("ğŸ’£ ç”Ÿæˆç­–ç•¥"):
        if not obj: st.warning("è¯·è¾“å…¥æ‹’ç»ç†ç”±")
        else:
            with st.spinner('å†›å¸ˆæ­£åœ¨æŸ¥é˜…è®°å¿†...'):
                PROMPT = f"""
                {KB_INJECTION}
                Negotiation Coach. Objection: "{obj}". 
                Context/Leverage: "{lev}" (If empty, use Knowledge Base info).
                Provide 3 strategies (Value, Empathy, Alternative).
                """
                res = robust_generate(PROMPT, valid_model_name)
                st.session_state.res_4 = res
    if st.session_state.res_4: st.markdown(st.session_state.res_4)

# --- åŠŸèƒ½äº”: å”®å (æ–°) ---
elif app_mode == MENU_OPTIONS[4]:
    st.subheader("ğŸ› ï¸ æ™ºèƒ½å”®å & äº§å“ä¸“å®¶é—®ç­”")
    
    if not current_memory:
        st.warning("âš ï¸ è®°å¿†åº“ä¸ºç©ºï¼è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF æˆ–ç²˜è´´èµ„æ–™ã€‚")
    else:
        st.success("âœ… è®°å¿†åº“åœ¨çº¿ã€‚AI å·²ç†Ÿè¯»ä½ æŠ•å–‚çš„æ‰€æœ‰èµ„æ–™ã€‚")
        
    question = st.text_input("è¯·è¾“å…¥é—®é¢˜ (å…³äºäº§å“/å”®å/å‚æ•°):")
    
    if 'res_5' not in st.session_state: st.session_state.res_5 = None
    
    if st.button("ğŸ¤– æé—®"):
        if not question: st.warning("è¯·è¾“å…¥é—®é¢˜")
        else:
            with st.spinner('æ­£åœ¨å›å¿†å†…éƒ¨èµ„æ–™...'):
                PROMPT = f"""
                {KB_INJECTION}
                Role: Senior Technical Support & Product Expert.
                User Question: "{question}"
                
                Task: Answer the question strictly based on the provided [LONG-TERM KNOWLEDGE BASE]. 
                If the answer is found, explain it clearly.
                """
                res = robust_generate(PROMPT, valid_model_name)
                st.session_state.res_5 = res
                
    if st.session_state.res_5:
        st.markdown("---")
        st.markdown(st.session_state.res_5)
